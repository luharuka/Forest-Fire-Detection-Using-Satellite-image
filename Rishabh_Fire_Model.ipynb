{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDbhPNcr8LdJ"
      },
      "outputs": [],
      "source": [
        "import os                                     # operating system\n",
        "import numpy as np                            # linear algebra\n",
        "from PIL import Image                         # Python image library\n",
        "import matplotlib.pyplot as plt               # making plots\n",
        "%matplotlib inline\n",
        "from IPython.display import display           # displaying ?\n",
        "\n",
        "import warnings                               # ignoring unnecessary python warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.applications import VGG16                         # pretrained CNN\n",
        "from keras.callbacks import ModelCheckpoint                  # furter train the saved model\n",
        "from keras import models, layers, optimizers                 # building DNN is keras\n",
        "from tensorflow.keras.models import load_model               # load saved model\n",
        "from keras.preprocessing.image import ImageDataGenerator     # preparing image data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg9lFRYK8QEu",
        "outputId": "21cbce58-86f5-4093-a48a-a6d2c5fef7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "conv_base = VGG16(weights='imagenet',\n",
        "                 include_top=False,\n",
        "                 input_shape=(150, 150, 3))\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "             metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK-pjJyF8b63",
        "outputId": "84f5a19a-98bd-4f69-867c-074274b8dafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5TOW1B08gNZ"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Forest Fire Dataset/Training')\n",
        "train_dir_fire = os.path.join(train_dir, 'fire')\n",
        "train_dir_nofire = os.path.join(train_dir, 'nofire')\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'Forest Fire Dataset/Testing')\n",
        "test_dir_fire = os.path.join(test_dir, 'fire')\n",
        "test_dir_nofire = os.path.join(test_dir, 'nofire')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aehiZtjp8y2v",
        "outputId": "30ea5e31-e0ee-486c-8458-834583947751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1520 images belonging to 2 classes.\n",
            "Found 369 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9TJwrY81wQ",
        "outputId": "75c271f9-c231-47b8-b75b-c5dd62c88910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "48/48 [==============================] - 576s 12s/step - loss: 0.4512 - acc: 0.7934 - val_loss: 0.3015 - val_acc: 0.8808\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 555s 12s/step - loss: 0.3121 - acc: 0.8704 - val_loss: 0.2377 - val_acc: 0.9268\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 587s 12s/step - loss: 0.2650 - acc: 0.8921 - val_loss: 0.2034 - val_acc: 0.9350\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 582s 12s/step - loss: 0.2302 - acc: 0.8980 - val_loss: 0.1720 - val_acc: 0.9485\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 549s 11s/step - loss: 0.2102 - acc: 0.9197 - val_loss: 0.1662 - val_acc: 0.9404\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 580s 12s/step - loss: 0.1987 - acc: 0.9224 - val_loss: 0.1927 - val_acc: 0.9268\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator, epochs=30,\n",
        "                    validation_data=test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Zv6aVuj86GH"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Untitled folder/VGG16_lr-4.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DQ5ebcJw9BFF"
      },
      "outputs": [],
      "source": [
        "# Dictionary to extract the numbers\n",
        "hist_dict = history.history\n",
        "\n",
        "# Training and validation accuracy\n",
        "training_acc = hist_dict['acc']\n",
        "validation_acc = hist_dict['val_acc']\n",
        "\n",
        "# Training and validation loss\n",
        "training_loss = hist_dict['loss']\n",
        "validation_loss = hist_dict['val_loss']\n",
        "\n",
        "# Number of epochs\n",
        "epoches = range(1, 1 + len(training_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "awNeznYf9D6P"
      },
      "outputs": [],
      "source": [
        "def plot_func(entity):\n",
        "\n",
        "    '''\n",
        "    This function produces plot to compare the performance\n",
        "    between train set and validation set.\n",
        "    entity can be loss of accuracy.\n",
        "    '''\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epoches, eval('training_' + entity), 'r')\n",
        "    plt.plot(epoches, eval('validation_' + entity), 'b')\n",
        "    plt.legend(['Training ' + entity, 'Validation ' + entity])\n",
        "    plt.xlabel('Epoches')\n",
        "    plt.ylabel(entity)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "twMwnEnA9FbS"
      },
      "outputs": [],
      "source": [
        "plot_func('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ak1hqmS-9HlP"
      },
      "outputs": [],
      "source": [
        "plot_func('acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YRt0V64X9JjG"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    else:\n",
        "        set_trainable = False\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "             metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WERtJXXn9LZP",
        "outputId": "31c799f4-fb3f-4c3a-ff90-e3e0ce838304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "48/48 [==============================] - 1691s 35s/step - loss: 0.1838 - acc: 0.9349 - val_loss: 0.0937 - val_acc: 0.9648\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 1687s 35s/step - loss: 0.0997 - acc: 0.9651 - val_loss: 0.0942 - val_acc: 0.9702\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 1674s 35s/step - loss: 0.0804 - acc: 0.9743 - val_loss: 0.1601 - val_acc: 0.9512\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 1685s 35s/step - loss: 0.0742 - acc: 0.9737 - val_loss: 0.0651 - val_acc: 0.9756\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 1681s 35s/step - loss: 0.0625 - acc: 0.9776 - val_loss: 0.0594 - val_acc: 0.9756\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 1674s 35s/step - loss: 0.0306 - acc: 0.9875 - val_loss: 0.0682 - val_acc: 0.9783\n",
            "Epoch 7/30\n",
            "18/48 [==========>...................] - ETA: 15:39 - loss: 0.0374 - acc: 0.9839"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(train_generator, epochs=30,\n",
        "                             validation_data=test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXz4Z4IF9OFX"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Untitled folder/VGG16_fine_tuned.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk0FlpOu9P03"
      },
      "outputs": [],
      "source": [
        "hist_dict = history.history\n",
        "\n",
        "training_accuracy = hist_dict['acc']\n",
        "validation_accuracy = hist_dict['val_acc']\n",
        "\n",
        "training_loss = hist_dict['loss']\n",
        "validation_loss = hist_dict['val_loss']\n",
        "\n",
        "epoches = range(1, 1 + len(training_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lybzNNkR9THU"
      },
      "outputs": [],
      "source": [
        "plot_func('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_KkF6rW9UyL"
      },
      "outputs": [],
      "source": [
        "plot_func('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CyBLiC59XGm"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = load_model('/content/drive/MyDrive/Untitled folder/VGG16_fine_tuned.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vlv1IzfB9ZQ-"
      },
      "outputs": [],
      "source": [
        "# taking first batch from the generator\n",
        "img, label = test_generator[0]\n",
        "\n",
        "# Predicting the images from the first batch\n",
        "pred = np.round(model.predict(img)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JwKpKbD9b0O"
      },
      "outputs": [],
      "source": [
        "len(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhIecgas9c84"
      },
      "outputs": [],
      "source": [
        "# Numeric to semantic labels\n",
        "label_dict = {1.0: 'No fire', 0.0: 'Fire'}\n",
        "\n",
        "# Generating collage of plots\n",
        "fig = plt.figure(figsize=(10, 9))\n",
        "plt.title('Classification by the model')\n",
        "plt.axis('off')\n",
        "\n",
        "for i, img_i in enumerate(img[:20]):\n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.title(label_dict[pred[i]], y=-0.2)\n",
        "    ax.imshow(img_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCE8Dkq09fh-"
      },
      "outputs": [],
      "source": [
        "# Lists for missed fire images and missed non-fire images\n",
        "msd_fire = []\n",
        "msd_nofire = []\n",
        "\n",
        "# Iterating through all the batches\n",
        "for j in range(31):\n",
        "    img, label = test_generator[j]\n",
        "    pred = np.round(model.predict(img)).flatten()\n",
        "    bool_list = label == pred\n",
        "\n",
        "    # bool_list is False when there is misclassification\n",
        "    for i, e in enumerate(bool_list):\n",
        "        if e == False:\n",
        "\n",
        "            # separating labels (fire and non-fire)\n",
        "            if label[i] == 0:\n",
        "                msd_fire.append(img[i])\n",
        "            else:\n",
        "                msd_nofire.append(img[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjPpVfh19iR2"
      },
      "outputs": [],
      "source": [
        "# total number of sample in train set in each class\n",
        "n_class = 1001\n",
        "\n",
        "# number of misclassified fire and non-fire images\n",
        "nm_fire, nm_nofire = len(msd_fire), len(msd_nofire)\n",
        "\n",
        "# confusion matrix (flattened)\n",
        "conf_mat = [n_class-nm_fire, nm_fire, nm_nofire, n_class-nm_nofire]\n",
        "\n",
        "# Plot the confusion matrix as an image\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "# visualization of confusion matrix\n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True labels')\n",
        "class_names=[\"fire\",\"nonfire\"]\n",
        "plt.xlabel('Predicted labels')\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=90)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "plt.axis()\n",
        "for i, j in enumerate(conf_mat):\n",
        "    ax = fig.add_subplot(2, 2, i+1)\n",
        "    ax.imshow([[j]], vmin=0, vmax=1000, cmap='copper_r')\n",
        "    ax.text(-0.2, 0.1, j, c='r', fontsize=30)\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# bringing blocks tighter\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8MFAvdO4I0-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aeQ_ZAs9mAD"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.title('Fire images classified as non-fire')\n",
        "plt.axis('off')\n",
        "for i, img_i in enumerate(msd_fire):\n",
        "    ax = fig.add_subplot(4, 5, i+1)\n",
        "    ax.imshow(img_i)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDL9UFrh9oVS"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 4))\n",
        "plt.title('Non-fire images classified as fire')\n",
        "plt.axis('off')\n",
        "for i, img_i in enumerate(msd_nofire):\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(img_i)\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ44Ql9-9qsW"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('VGG16_fine_tuned.h5',\n",
        "                             monitor='loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I86cOqJA9rwZ"
      },
      "outputs": [],
      "source": [
        "hst_cntd = model.fit(train_generator, epochs=5,\n",
        "                     steps_per_epoch = 15,\n",
        "                     validation_data=test_generator,\n",
        "                     validation_steps = 30,\n",
        "                     callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEJRIXPb1vtj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Create an empty dataframe\n",
        "data = pd.DataFrame(columns=['image_path', 'label'])\n",
        "\n",
        "# Define the labels/classes\n",
        "labels = {'/content/drive/MyDrive/Forest Fire Dataset/Training/fire' : 'Fire',\n",
        "          '/content/drive/MyDrive/Forest Fire Dataset/Training/nofire' : 'No Fire',\n",
        "           }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LmV4a__AMCr"
      },
      "outputs": [],
      "source": [
        "# Loop over the train, test, and val folders and extract the image path and label\n",
        "for folder in labels:\n",
        "    for image_name in os.listdir(folder):\n",
        "        image_path = os.path.join(folder, image_name)\n",
        "        label = labels[folder]\n",
        "        data = data.append({'image_path': image_path, 'label': label}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE3oOym-ATTK"
      },
      "outputs": [],
      "source": [
        "data.to_csv('image_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcaTIZTaAXc1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka_LHJGtAfFE"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/image_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLX6KeWmAkLo"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw2bBNQ0As-W"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TykxL-xAxEx"
      },
      "outputs": [],
      "source": [
        "# Pre-process the data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=45,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
        "                                                    x_col=\"image_path\",\n",
        "                                                    y_col=\"label\",\n",
        "                                                    target_size=(255, 255),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode=\"categorical\")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
        "                                                  x_col=\"image_path\",\n",
        "                                                  y_col=\"label\",\n",
        "                                                  target_size=(255, 255),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLs3bG-VBJCV"
      },
      "outputs": [],
      "source": [
        "# Build a deep learning model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(255, 255, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewbm1X7FBSZ4"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhyYFc5OBUni"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator, epochs=30,validation_data=test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSshx9eNBWkF"
      },
      "outputs": [],
      "source": [
        "num_samples = test_df.shape[0]\n",
        "num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0yohecpCZ8n"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(test_generator,\n",
        "                       steps=num_samples//32+1,\n",
        "                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQIaJWO1Ccef"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# Plot the accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9efVVmeC2hP"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('Model.h5')\n",
        "# Load the model\n",
        "model = load_model(\"Model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRit-7YYDGAy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Define the class names\n",
        "class_names = ['Fire','No Fire']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOTQVDn4DM-_"
      },
      "outputs": [],
      "source": [
        "# Load an image from the test set\n",
        "img = load_img(\"/content/drive/MyDrive/Forest Fire Dataset/Testing/fire_0015.jpg\", target_size=(255, 255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERN7HvliDfxn"
      },
      "outputs": [],
      "source": [
        "# Convert the image to an array\n",
        "img_array = img_to_array(img)\n",
        "img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBlkoWrPDhlQ"
      },
      "outputs": [],
      "source": [
        "img_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2nf9BXqDlsh"
      },
      "outputs": [],
      "source": [
        "# Normalize the image pixel values to the range [0, 1]\n",
        "img_array = img_array / 255.0\n",
        "img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3SnhxUGDpLp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "img_array = np.reshape(img_array, (1, 255, 255, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v_cT5hmDuAH"
      },
      "outputs": [],
      "source": [
        "# Get the model predictions\n",
        "predictions = model.predict(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1QH58mwDwI7"
      },
      "outputs": [],
      "source": [
        "# Get the class index with the highest predicted probability\n",
        "class_index = np.argmax(predictions[0])\n",
        "\n",
        "# Get the predicted class label\n",
        "predicted_label = class_names[class_index]\n",
        "\n",
        "print(\"The image is predicted to be '{}'.\".format(predicted_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_tFWFwPDzLU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCQlSVYeENUS"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict_generator(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gMO1X6cENrn"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqCmj-cwEQfp"
      },
      "outputs": [],
      "source": [
        "actual_labels = test_generator.classes\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "predicted_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb76KtGKEVrk"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(actual_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTkzhlOMEWHz"
      },
      "outputs": [],
      "source": [
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh9NUUwuEZWn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Confusion matrix\n",
        "\n",
        "\n",
        "# Plot the confusion matrix as an image\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "\n",
        "# Add the class labels to the plot\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=45)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# Add values to the plot\n",
        "threshold = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j],\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > threshold else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel(\"True label\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kKStCCSEjWv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}